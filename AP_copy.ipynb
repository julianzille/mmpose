{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f54e546-43df-439b-b09f-72f5f24b9b06",
   "metadata": {},
   "source": [
    "#### Extract all AcinoSet data and merge all .csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35509f-ff5a-4e95-8916-ec0257cd31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# NB: unzip \"labelled_data.zip\" to \"/notebooks/data/acino/labelled\" first\n",
    "\n",
    "acino='/notebooks/data/acino'\n",
    "\n",
    "img_ids=[os.path.splitext(img)[0] for img in os.listdir(acino+'/../ap10k/data/')]\n",
    "img_ids.remove('.ipynb_checkpoints')\n",
    "img_ids=[int(i) for i in img_ids]\n",
    "img_no=max(img_ids)+1\n",
    "\n",
    "base=pd.read_csv('base.csv')\n",
    "\n",
    "for dir in os.listdir(acino+'/labelled'): #JamesFlick1 JamesFlick2 etc.\n",
    "    print(dir)\n",
    "    if os.path.isdir(acino+'/labelled/'+dir):\n",
    "        \n",
    "        df=pd.read_csv('labelled/'+dir+'/'+\"CollectedData_UCT.csv\")\n",
    "\n",
    "        df.iloc[0,1:]=df.iloc[0,1:].astype(str) +'_'+ df.iloc[1,1:].astype(str)\n",
    "        df.columns=df.iloc[0] # Make keypoint labels column headers\n",
    "        df=df.iloc[2:,:]\n",
    "        \n",
    "        #Extract COCO keypoints (AP10K):\n",
    "        #df=df.reindex(columns=(['bodyparts','l_eye_x','l_eye_y','r_eye_x','r_eye_y','nose_x','nose_y','neck_base_x','neck_base_y','tail_base_x','tail_base_y','l_shoulder_x','l_shoulder_y','l_front_knee_x','l_front_knee_y','l_front_paw_x','l_front_paw_y','r_shoulder_x','r_shoulder_y','r_front_knee_x','r_front_knee_y','r_front_paw_x','r_front_paw_y','l_hip_x','l_hip_y','l_back_knee_x','l_back_knee_y','l_back_paw_x','l_back_paw_y','r_hip_x','r_hip_y','r_back_knee_x','r_back_knee_y','r_back_paw_x','r_back_paw_y','tail2_x','tail2_y']))\n",
    "        \n",
    "        #Extract COCO keypoints (All Acino Keypoints):\n",
    "        df=df.reindex(columns=(['bodyparts','l_eye_x','l_eye_y','r_eye_x','r_eye_y','nose_x','nose_y','neck_base_x','neck_base_y','tail_base_x','tail_base_y','l_shoulder_x','l_shoulder_y','l_front_knee_x','l_front_knee_y','l_front_paw_x','l_front_paw_y','r_shoulder_x','r_shoulder_y','r_front_knee_x','r_front_knee_y','r_front_paw_x','r_front_paw_y','l_hip_x','l_hip_y','l_back_knee_x','l_back_knee_y','l_back_paw_x','l_back_paw_y','r_hip_x','r_hip_y','r_back_knee_x','r_back_knee_y','r_back_paw_x','r_back_paw_y','tail2_x','tail2_y','tail1_x','tail1_y','r_front_ankle_x','r_front_ankle_y','l_front_ankle_x','l_front_ankle_y','r_back_ankle_x','r_back_ankle_y','l_back_ankle_x','l_back_ankle_y','spine_x','spine_y']))\n",
    "        \n",
    "        for i in range(0,len(df)): # Iterate over rows\n",
    "            orig=df.iloc[i,0].split('/')[2]\n",
    "            df.iloc[i,0]='as_'+str(img_no)+'.jpg'\n",
    "            \n",
    "            im=Image.open('data/acino/labelled/'+dir+'/'+orig)\n",
    "            img_name='as_'+str(img_no)\n",
    "            im.save('data/acino/data/'+img_name+'.jpg')\n",
    "            \n",
    "            #os.remove('labelled1/'+dir+'/'+orig)\n",
    "            \n",
    "            \n",
    "            img_no+=1\n",
    "        base=pd.concat([base,df[0:]],ignore_index=True)\n",
    "               \n",
    "base.to_csv(\"data/acino/annotations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e1e27-5ee6-4555-bfa7-3fe784419c67",
   "metadata": {},
   "source": [
    "#### Convert .csv labels to COCO .json format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d8406-440c-4693-a9be-107e22cf6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "df = pd.read_csv('data/acino/annotations.csv')\n",
    "\n",
    "with open('data/acino/annotations/acino_all.json','r+') as f: # Save all annotation instances in one .json file\n",
    "    anns_data=json.load(f)\n",
    "    \n",
    "    for i in range(0,len(df)):# Iterate over each image\n",
    "\n",
    "        #Add image instance\n",
    "        img_name=df.iloc[i,0]\n",
    "        img_id=int(img_name[3:].split('.')[0])\n",
    "        img=cv2.imread('data/acino/data/'+img_name)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        img_inst=dict(width=width,height=height,file_name=img_name,background=1,id=img_id)\n",
    "        \n",
    "        #Add annotation instance\n",
    "        ann_id=img_id\n",
    "        kp=[]\n",
    "        num_kp=0\n",
    "\n",
    "        # Initial bbox:\n",
    "        x_min=width-1\n",
    "        x_max=1\n",
    "        y_min=height-1\n",
    "        y_max=1\n",
    "\n",
    "        for j in range(1,len(df.columns),2):\n",
    "            if pd.isnull(df.iloc[i,j]): #NaN values\n",
    "                kp.append(0)\n",
    "                kp.append(0)\n",
    "                kp.append(0)\n",
    "                \n",
    "            else:\n",
    "                x=int(round(pd.to_numeric(df.iloc[i,j])))\n",
    "                y=int(round(pd.to_numeric(df.iloc[i,j+1])))\n",
    "                \n",
    "                #Add annotations\n",
    "                kp.append(x)\n",
    "                kp.append(y)\n",
    "                kp.append(2)\n",
    "                num_kp+=1\n",
    "\n",
    "                #Bbox\n",
    "                if x<x_min:\n",
    "                    x_min=x\n",
    "                if x>x_max:\n",
    "                    x_max=x\n",
    "                if y>y_max:\n",
    "                    y_max=y\n",
    "                if y<y_min:\n",
    "                    y_min=y\n",
    "\n",
    "        w=max(1,(x_max-x_min)) # BBox width\n",
    "        h=max(1,(y_max-y_min)) # BBox height\n",
    "        a=w*h # Bbox area\n",
    "        \n",
    "        #Padded bounding box:\n",
    "        bbox=[x_min-15,y_min-15,w+30,h+30] # xywh format NB! y_min==top left corner\n",
    "        \n",
    "#         if not kp[-1]==0: # If tip of tail != NaN\n",
    "#             num_kp-=1 \n",
    "            \n",
    "#         del kp[-3:] # Remove tail_x, tail_y, visible\n",
    "        \n",
    "        \n",
    "        ann_inst=dict(image_id=img_id,iscrowd=0,category_id=25,num_keypoints=num_kp,keypoints=kp,bbox=bbox,id=ann_id,area=a)\n",
    "        anns_data['images'].append(img_inst)\n",
    "        anns_data['annotations'].append(ann_inst)\n",
    "    f.seek(0)\n",
    "    json.dump(anns_data,f,indent=4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e36c3-67ee-407b-be32-ddf9e6458ced",
   "metadata": {},
   "source": [
    "#### Train-test-val split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531d2b4-74df-4e44-b2ca-21307bf4893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install echo1-coco-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc83f7-c1cd-410f-ac66-cbdea9c17875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!coco-split --annotations_file data/acino/annotations/acino_all.json --valid_ratio 0.1 --test_ratio 0.2 --train_name data/acino/annotations/acino_train.json --valid_name data/acino/annotations/acino_val.json --test_name data/acino/annotations/acino_test.json --has_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf8949-29ee-4615-b38f-0491a51cbe04",
   "metadata": {},
   "source": [
    "#### Train Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94c027-f772-4991-8ed4-0ec6323b83cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
    "%pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# install mmcv-full thus we could use CUDA operators\n",
    "%pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
    "\n",
    "# install mmdet for inference demo\n",
    "%pip install mmdet\n",
    "\n",
    "# install mmpose dependencies\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# install mmpose in develop mode\n",
    "%pip install -e .\n",
    "\n",
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "\n",
    "# print('torch version:', torch.__version__, torch.cuda.is_available())\n",
    "# print('torchvision version:', torchvision.__version__)\n",
    "\n",
    "# # Check MMPose installation\n",
    "# import mmpose\n",
    "\n",
    "# print('mmpose version:', mmpose.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "# from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "\n",
    "# print('cuda version:', get_compiling_cuda_version())\n",
    "# print('compiler information:', get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05634697-c9a7-4cd3-8228-4fa39376590a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config file:\n",
    "from mmcv import Config\n",
    "import mmcv\n",
    "import mmpose\n",
    "import torch, torchvision\n",
    "\n",
    "cfg = Config.fromfile('configs/animal/2d_kpt_sview_rgb_img/topdown_heatmap/acino/hrnet_w32_acino_256x256.py'\n",
    "    #'./configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w32_coco_256x192.py'\n",
    ")\n",
    "# cfg.data_root = 'data'\n",
    "# cfg.work_dir = 'work_dirs/hrnet_w32_acino_256x256'\n",
    "# cfg.data['train']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_train.json'\n",
    "# cfg.data['train']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "# cfg.data['test']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_test.json'\n",
    "# cfg.data['test']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "# cfg.data['val']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_val.json'\n",
    "# cfg.data['val']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "# cfg.gpu_ids = range(1)\n",
    "# cfg.seed = 0\n",
    "cfg.total_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87b318ab-83b0-4495-9e32-94eec80d0f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnimalPose.ipynb  ap-10k.zip\t     mmpose\t       setup.cfg\n",
      "CITATION.cff\t  configs\t     mmpose.egg-info   setup.py\n",
      "LICENSE\t\t  data\t\t     model-index.yml   tests\n",
      "MANIFEST.in\t  demo\t\t     pytest.ini        tools\n",
      "PAT.txt\t\t  docker\t     requirements      vis_result\n",
      "README.md\t  docs\t\t     requirements.txt  work_dirs\n",
      "README_CN.md\t  labelled_data.zip  resources\t       workflow.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f3caf-1aad-4a75-b31a-d5f0bd8c3235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train from config file\n",
    "from mmpose.datasets import build_dataset\n",
    "from mmpose.models import build_posenet\n",
    "from mmpose.apis import train_model\n",
    "\n",
    "# build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "\n",
    "# build model\n",
    "model = build_posenet(cfg.model)\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(cfg.work_dir)\n",
    "\n",
    "# train model\n",
    "train_model(\n",
    "    model, datasets, cfg, distributed=False, validate=True, meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0032793-06fc-4319-9c8e-ec9b995f7f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T14:09:29.775913Z",
     "iopub.status.busy": "2022-09-12T14:09:29.775527Z",
     "iopub.status.idle": "2022-09-12T14:09:32.073682Z",
     "shell.execute_reply": "2022-09-12T14:09:32.072524Z",
     "shell.execute_reply.started": "2022-09-12T14:09:29.775887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: work_dirs/hrnet_w32_acino_256x256/latest.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2/2, 1.4 task/s, elapsed: 1s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# Test model:\n",
    "from matplotlib import pprint\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result, process_mmdet_results)\n",
    "# from mmdet.apis import inference_detector, init_detector\n",
    "from xtcocotools.coco import COCO\n",
    "import os\n",
    "# import cv2\n",
    "local_runtime = False\n",
    "\n",
    "# try:\n",
    "#     from google.colab.patches import cv2_imshow  # for image visualization in colab\n",
    "# except:\n",
    "#     local_runtime = True\n",
    "from mmpose.datasets import DatasetInfo\n",
    "\n",
    "pose_checkpoint = 'work_dirs/hrnet_w32_acino_256x256/latest.pth'\n",
    "json_file='tests/data/acino/testacino.json'\n",
    "coco = COCO(json_file)\n",
    "img_keys = list(coco.imgs.keys())\n",
    "\n",
    "# initialize pose model\n",
    "pose_model = init_pose_model(cfg, pose_checkpoint)\n",
    "\n",
    "dataset = pose_model.cfg.data['test']['type']\n",
    "dataset_info = pose_model.cfg.data['test'].get('dataset_info', None)\n",
    "dataset_info = DatasetInfo(dataset_info)\n",
    "return_heatmap=False\n",
    "output_layer_names=None\n",
    "\n",
    "for i in mmcv.track_iter_progress(range(len(img_keys))):\n",
    "  # get bounding box annotations\n",
    "  image_id = img_keys[i]\n",
    "  #print(\"\\nID:\",image_id,\"\\n\")\n",
    "  image = coco.loadImgs(image_id)[0]\n",
    "  #print(\"\\nID:\",image,\"\\n\")\n",
    "  image_name = os.path.join('tests/data/acino', image['file_name'])\n",
    "  #print(\"\\nID:\",image_name,\"\\n\")\n",
    "  ann_ids = coco.getAnnIds(image_id)\n",
    "  \n",
    "  person_results = []\n",
    "  for ann_id in ann_ids:\n",
    "    person = {}\n",
    "    ann = coco.anns[ann_id]\n",
    "    \n",
    "    # bbox format is 'xywh'\n",
    "    person['bbox'] = ann['bbox']\n",
    "    person_results.append(person)\n",
    "    # print('\\n')\n",
    "    # print(person_results)\n",
    "    # print('\\n')\n",
    "\n",
    "  pose_results, returned_outputs = inference_top_down_pose_model(\n",
    "    pose_model,\n",
    "    image_name,\n",
    "    person_results=person_results,##\n",
    "    bbox_thr=None,\n",
    "    format='xywh',\n",
    "    dataset=dataset,\n",
    "    dataset_info=dataset_info,\n",
    "    return_heatmap=return_heatmap,\n",
    "    outputs=output_layer_names)\n",
    "  \n",
    "  os.makedirs('vis_result', exist_ok=True)\n",
    "  out_file = os.path.join('vis_result', f'vis_as{image_id}.jpg')\n",
    "  vis_result=vis_pose_result(pose_model,image_name,pose_results,radius=3,thickness=1,out_file=out_file)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8578c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (4.34.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn) (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71b1fc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot curve of work_dirs/hrnet_w32_acino_256x256/None.log.json, metric is acc_pose\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/tools/analysis/analyze_logs.py\", line 167, in <module>\n",
      "    main()\n",
      "  File \"/notebooks/tools/analysis/analyze_logs.py\", line 163, in main\n",
      "    eval(args.task)(log_dicts, args)\n",
      "  File \"/notebooks/tools/analysis/analyze_logs.py\", line 68, in plot_curve\n",
      "    plt.plot(xs, ys, label=legend[i * num_metrics + j], linewidth=0.5)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\", line 2769, in plot\n",
      "    return gca().plot(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_axes.py\", line 1632, in plot\n",
      "    lines = [*self._get_lines(*args, data=data, **kwargs)]\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py\", line 312, in __call__\n",
      "    yield from self._plot_args(this, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py\", line 498, in _plot_args\n",
      "    raise ValueError(f\"x and y must have same first dimension, but \"\n",
      "ValueError: x and y must have same first dimension, but have shapes (17022,) and (17012,)\n"
     ]
    }
   ],
   "source": [
    "! python tools/analysis/analyze_logs.py plot_curve work_dirs/hrnet_w32_acino_256x256/None.log.json --keys acc_pose\n",
    "# from tools.analysis.analyze_logs import plot_curve\n",
    "\n",
    "# log_file='work_dirs/hrnet_w32_acino_256x256/None.log.json'\n",
    "\n",
    "# figs=plot_curve(log_file, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
