{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35509f-ff5a-4e95-8916-ec0257cd31da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94c027-f772-4991-8ed4-0ec6323b83cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
    "%pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# install mmcv-full thus we could use CUDA operators\n",
    "%pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
    "\n",
    "# install mmdet for inference demo\n",
    "%pip install mmdet\n",
    "\n",
    "# install mmpose dependencies\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# install mmpose in develop mode\n",
    "%pip install -e .\n",
    "\n",
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "\n",
    "print('torch version:', torch.__version__, torch.cuda.is_available())\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "\n",
    "# Check MMPose installation\n",
    "import mmpose\n",
    "\n",
    "print('mmpose version:', mmpose.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "# from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "\n",
    "# print('cuda version:', get_compiling_cuda_version())\n",
    "# print('compiler information:', get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05634697-c9a7-4cd3-8228-4fa39376590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "import mmcv\n",
    "\n",
    "cfg = Config.fromfile('configs/animal/2d_kpt_sview_rgb_img/topdown_heatmap/ap10k/hrnet_w32_ap10k_256x256.py'\n",
    "    #'./configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w32_coco_256x192.py'\n",
    ")\n",
    "cfg.data_root = 'data'\n",
    "cfg.work_dir = 'work_dirs/hrnet_w32_acino_256x256'\n",
    "cfg.data['train']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_train.json'\n",
    "cfg.data['train']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "cfg.data['test']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_test.json'\n",
    "cfg.data['test']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "cfg.data['val']['ann_file']=f'{cfg.data_root}/acino/annotations/acino_val.json'\n",
    "cfg.data['val']['img_prefix']=f'{cfg.data_root}/acino/data/'\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.seed = 0\n",
    "cfg.total_epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b318ab-83b0-4495-9e32-94eec80d0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f3caf-1aad-4a75-b31a-d5f0bd8c3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmpose.datasets import build_dataset\n",
    "from mmpose.models import build_posenet\n",
    "from mmpose.apis import train_model\n",
    "\n",
    "# build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# build model\n",
    "model = build_posenet(cfg.model)\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(cfg.work_dir)\n",
    "\n",
    "# train model\n",
    "train_model(\n",
    "    model, datasets, cfg, distributed=False, validate=True, meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0032793-06fc-4319-9c8e-ec9b995f7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pprint\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result, process_mmdet_results)\n",
    "# from mmdet.apis import inference_detector, init_detector\n",
    "from xtcocotools.coco import COCO\n",
    "import os\n",
    "# import cv2\n",
    "local_runtime = False\n",
    "\n",
    "# try:\n",
    "#     from google.colab.patches import cv2_imshow  # for image visualization in colab\n",
    "# except:\n",
    "#     local_runtime = True\n",
    "from mmpose.datasets import DatasetInfo\n",
    "\n",
    "pose_checkpoint = 'work_dirs/hrnet_w32_acino_256x256/latest.pth'\n",
    "json_file='tests/data/acino/testacino.json'\n",
    "coco = COCO(json_file)\n",
    "img_keys = list(coco.imgs.keys())\n",
    "\n",
    "# initialize pose model\n",
    "pose_model = init_pose_model(cfg, pose_checkpoint)\n",
    "\n",
    "dataset = pose_model.cfg.data['test']['type']\n",
    "dataset_info = pose_model.cfg.data['test'].get('dataset_info', None)\n",
    "dataset_info = DatasetInfo(dataset_info)\n",
    "return_heatmap=False\n",
    "output_layer_names=None\n",
    "\n",
    "for i in mmcv.track_iter_progress(range(len(img_keys))):\n",
    "  # get bounding box annotations\n",
    "  image_id = img_keys[i]\n",
    "  #print(\"\\nID:\",image_id,\"\\n\")\n",
    "  image = coco.loadImgs(image_id)[0]\n",
    "  #print(\"\\nID:\",image,\"\\n\")\n",
    "  image_name = os.path.join('tests/data/acino', image['file_name'])\n",
    "  #print(\"\\nID:\",image_name,\"\\n\")\n",
    "  ann_ids = coco.getAnnIds(image_id)\n",
    "  \n",
    "  person_results = []\n",
    "  for ann_id in ann_ids:\n",
    "    person = {}\n",
    "    ann = coco.anns[ann_id]\n",
    "    \n",
    "    # bbox format is 'xywh'\n",
    "    person['bbox'] = ann['bbox']\n",
    "    person_results.append(person)\n",
    "    # print('\\n')\n",
    "    # print(person_results)\n",
    "    # print('\\n')\n",
    "\n",
    "  pose_results, returned_outputs = inference_top_down_pose_model(\n",
    "    pose_model,\n",
    "    image_name,\n",
    "    person_results=person_results,##\n",
    "    bbox_thr=None,\n",
    "    format='xywh',\n",
    "    dataset=dataset,\n",
    "    dataset_info=dataset_info,\n",
    "    return_heatmap=return_heatmap,\n",
    "    outputs=output_layer_names)\n",
    "  \n",
    "  os.makedirs('vis_result', exist_ok=True)\n",
    "  out_file = os.path.join('vis_result', f'vis_as{image_id}.jpg')\n",
    "  vis_result=vis_pose_result(pose_model,image_name,pose_results,radius=6,thickness=3,out_file=out_file)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
